Data Scientist &
Développeur d’application en Intelligence Artificiel 2023-2025
















            










Bloc de compétences 2 - E2
Intégrer des modèles et des services 
d’intelligence artificielle








ABID Samuel




Marseille - Nice
________________


Sommaire




Introduction        4
A3. Compétence : Intégration de services d'intelligence artificielle préexistants        5
C6. Veille Technologique et Réglementaire        5
Définir la ou les thématiques de veille.        5
Planifier les temps dédiés à la veille.        5
Choisir un outil d'agrégation des flux d’informations et d’actualités.        5
Choisir un outil de partage ou communication des synthèses des informations collectées.        5
Identifier les sources et les flux d’informations utiles à la veille thématique visée.        5
Qualifier la fiabilité des sources et des flux identifiés.        5
Configurer les outils d’agrégation selon les flux et sources et la ou les thématiques de veille.        5
Rédiger des synthèses des informations collectées.        5
Communiquer les synthèses aux parties prenantes du projet.        5
C7. Identification et Benchmark de Services d'IA        5
Définir la problématique technique et fonctionnelle d’intelligence artificielle à adresser.        5
Identifier les contraintes de moyens, techniques et opérationnelles liées au contexte du projet.        6
Benchmarker les outils et services d’intelligence artificielle accessibles et répondant au problème visé.        6
Rédiger des conclusions préconisant un ou plusieurs services d’intelligence artificielle.        6
C8. Paramétrage et Intégration d'un Service d'IA        6
Créer l’environnement d'exécution du service.        6
Installer et configurer les éventuelles dépendances.        6
Créer les accès à l’environnement d’exécution et de configuration du service.        6
Installer et configurer les outils de monitorage disponibles avec le service intégré.        6
Rédiger la documentation technique.        6
Conclusion        7
Annexes        8
________________
Introduction


Notre projet E2 s'inscrit dans une démarche d'évaluation et de comparaison des performances de différents modèles de Deep Learning pour la classification d'images alimentaires. En utilisant le dataset Food-101, qui contient 101 catégories différentes d'aliments, nous avons développé un système de benchmark complet et automatisé.


Les objectifs principaux sont :
* Évaluer les performances de différents modèles de classification d'images (ResNet-50, EfficientNet-B0, MobileNetV3)
* Comparer leur efficacité en termes de précision et de temps d'entraînement
* Fournir des recommandations basées sur des métriques concrètes
* Mettre en place un système de monitoring et d'analyse des résultats
* Analyser les confusions entre classes similaires
* Générer des visualisations détaillées des performances




Le projet intègre plusieurs aspects techniques essentiels :
* Une architecture modulaire et maintenable
* Un système de monitoring complet avec MLflow
* Des outils de visualisation des résultats
* Une gestion efficace des ressources
* Une analyse approfondie des confusions entre classes
* Des métriques avancées de performance














le projet consiste en 
MDP : AshBashCash@7Simplon//78@@M


User : ABID-SAMUEL




________________
A3. Compétence : Intégration de services d'intelligence artificielle préexistants
C6. Veille Technologique et Réglementaire
Définir la ou les thématiques de veille.
Dans le cadre du projet Food-101, nous avons défini plusieurs thématiques de veille stratégiques :
* Deep Learning pour la classification d'images
* Techniques d'optimisation et d'entraînement
* Avancées en transfer learning
* Frameworks et outils
* Mises à jour de PyTorch et ses composants
* Outils de monitoring et benchmarking
* Datasets de classification alimentaire
* Techniques de prétraitement d'images
* Bonnes pratiques en matière de gestion des données


Planifier les temps dédiés à la veille.
Veille quotidienne (30 min)
* Consultation des flux RSS techniques
* Suivi des repositories GitHub pertinents
* Lecture des newsletters spécialisées
Veille hebdomadaire (2h)
* Lundi : Analyse des nouveaux papiers et modèles
* Mercredi : Revue des frameworks et outils
* Vendredi : Synthèse et documentation
Veille mensuelle (1 jour)
* Analyse approfondie des tendances
* Tests des nouvelles technologies prometteuses
* Mise à jour de la documentation technique




Choisir un outil d'agrégation des flux d’informations et d’actualités.


Sources primaires
GitHub Trending pour le code source
Agrégateurs spécialisés
Reddit (r/MachineLearning, r/deeplearning)
Twitter/X (listes techniques dédiées)
Newsletters
PyTorch Weekly
Machine Learning Monthly
Data Science Weekly


Choisir un outil de partage ou communication des synthèses des informations collectées.


Les outils de partage de communication utilisé sont : 
* GitHub pour le versionnement et le partage de code
* MLflow pour le suivi des expériences et métriques


Identifier les sources et les flux d’informations utiles à la veille thématique visée.
Documentation officielle
PyTorch (pytorch.org)
TensorFlow (tensorflow.org)
Papers with Code (paperswithcode.com)
Ressources Vidéo
Webinars spécialisés
Tuto Youtube


Qualifier la fiabilité des sources et des flux identifiés.
Mon processus de qualification des sources suit plusieurs critères :


Critères techniques
Reproductibilité des résultats
Documentation détaillée
Critères de fiabilité
Réputation de la source
Fréquence de mise à jour
Activité de la communauté


Configurer les outils d’agrégation selon les flux et sources et la ou les thématiques de veille.


1. Utilisation d'Agrégateurs de Flux:
Outil Utilisé: Feedly
Mise en Place: Abonnement aux flux RSS des sites de documentation officielle tels que PyTorch et TensorFlow, ainsi qu'aux newsletters spécialisées comme PyTorch Weekly, Machine Learning Monthly, et Data Science Weekly. Cela permet de recevoir automatiquement les dernières mises à jour et publications pertinentes.
2. Suivi des Réseaux Sociaux:


Twitter/X: Création de listes dédiées pour suivre les experts en intelligence artificielle et deep learning, afin de rester informé des discussions et tendances actuelles.


Reddit: Participation aux discussions sur des subreddits comme r/MachineLearning et r/deeplearning pour découvrir des insights communautaires et des innovations partagées par d'autres professionnels du domaine.






3. Centralisation des Informations:
Outil Utilisé: Google Drive
Mise en Place: Création d'un dossier structuré sur Google Drive pour centraliser toutes les informations collectées. Organisation des documents par thématiques de veille, par exemple, "Deep Learning", "Frameworks", "Techniques d'Optimisation", etc. Utilisation de documents Google pour rédiger des synthèses régulières des informations collectées et partage facile avec l'équipe.




Rédiger des synthèses des informations collectées.


Dans le cadre du projet Food-101, nous avons effectué une série de benchmarks pour évaluer les performances de différents modèles de Deep Learning sur la tâche de classification d'images alimentaires. Les modèles testés incluent ResNet-50, EfficientNet-B0, et MobileNetV3. Voici les principaux résultats et conclusions :


1. Modèles et Performances :
* EfficientNet-B0 s'est révélé être le modèle le plus performant avec une précision de 71.05% lors du benchmark complet. Il offre un bon équilibre entre précision et temps d'entraînement, ce qui en fait notre recommandation principale pour les cas nécessitant une haute précision.
* MobileNetV3 a montré des performances satisfaisantes avec une précision de 59.77% et un temps d'entraînement réduit, ce qui le rend adapté aux environnements avec des ressources limitées.
* ResNet-50, bien que populaire, a montré des performances décevantes dans notre contexte spécifique avec une précision de seulement 11.71%.




2. Recommandations :
* Adopter EfficientNet-B0 comme modèle principal pour sa précision et son efficacité en termes de ressources.
* Utiliser MobileNetV3 dans des environnements contraints par les ressources.
* Continuer l'optimisation des hyperparamètres pour améliorer les performances globales.




3. Approche et Méthodologie :
* Le projet a intégré une architecture modulaire et maintenable, facilitant l'ajout de nouveaux modèles et l'extension à d'autres datasets alimentaires.
* Un système de monitoring détaillé a été mis en place pour suivre les performances des modèles et optimiser les ressources utilisées.
4. Perspectives d'Évolution :
* Intégration de nouveaux modèles pour élargir le champ d'application.
* Optimisation continue des performances et amélioration du système de monitoring.
* Extension à d'autres datasets pour renforcer la robustesse et la généralisation des modèles.
Ma synthèse montre l'importance d'une approche structurée et méthodique dans l'évaluation des modèles d'IA, fournissant une base solide pour de futures améliorations et comparaisons.


Communiquer les synthèses aux parties prenantes du projet.
Notre stratégie de communication s'articule autour de plusieurs canaux :
Communication technique
* Documentation en ligne
* Rapports de benchmark
* Présentations techniques
Communication projet
* Réunions hebdomadaires
* Mails de synthèse
* Dashboard de suivi
Partage de connaissances
* Wiki technique
* Sessions de formation
* Présentations des nouvelles technologies
Cette approche structurée de la veille technologique nous permet de maintenir le projet à jour et d'anticiper les évolutions technologiques pertinentes pour notre benchmark Food-101.


C7. Identification et Benchmark de Services d'IA
Définir la problématique technique et fonctionnelle d’intelligence artificielle à adresser.
Le projet Food-101 vise à résoudre un problème de classification d'images alimentaires avec les caractéristiques suivantes :
* Besoin d'identifier et classifier automatiquement 101 types d'aliments différents
* Utilisation dans un contexte réel avec des photos prises par des utilisateurs
* Nécessité d'une solution robuste et performante


Enjeux technique : 
* Gestion d'un large dataset (101 classes, milliers d'images)
* Traitement d'images de qualité variable (luminosité, angle, résolution)
* Besoin d'un bon équilibre entre précision et rapidité d'exécution


Identifier les contraintes de moyens, techniques et opérationnelles liées au contexte du projet.
Contraintes matérielles
* Budget limité pour l'infrastructure
* Nécessité de fonctionner sur des configurations modestes
* Optimisation des ressources GPU/CPU
Contraintes temporelles
* Temps d'entraînement raisonnable
* Réponse rapide en production
* Maintenance et mises à jour régulières
Contraintes légales et éthiques
* Respect des licences des datasets
* Gestion des droits d'utilisation des images


Benchmarker les outils et services d’intelligence artificielle accessibles et répondant au problème visé.
Critères d'évaluation
* Précision de la classification
* Temps d'entraînement et d'inférence
* Consommation de ressources
* Facilité de déploiement et maintenance
Résultats clés
* EfficientNet-B0 : Meilleur compromis (71.05% précision)
* MobileNetV3 : Solution légère (59.77% précision)
* ResNet-50 : Performance décevante (11.71% précision)


Rédiger des conclusions préconisant un ou plusieurs services d’intelligence artificielle.
Recommandation principale
* Adoption d'EfficientNet-B0 comme modèle principal
* Justification : meilleure précision, temps d'entraînement acceptable, bonne optimisation des ressources
Alternatives
* MobileNetV3 pour les environnements contraints
* Possibilité d'ensemble de modèles pour cas spécifiques
Plan d'implémentation
1. Phase pilote avec EfficientNet-B0
2. Optimisation des hyperparamètres
3. Mise en place d'un système de monitoring
4. Évaluation continue des performances
Cette approche structurée me permet de justifier le choix d'EfficientNet-B0 comme solution principale, tout en gardant la flexibilité nécessaire pour s'adapter aux différents cas d'usage.
C8. Paramétrage et Intégration d'un Service d'IA
Créer l’environnement d'exécution du service.
Structure du projet
* Organisation modulaire du code
* Séparation claire des composants (benchmarking, monitoring, visualisation)
* Gestion des configurations par environnement
Gestion des ressources
* Isolation de l'environnement via .gitignore
* Gestion des données volumineuses (dataset Food-101)
* Organisation des résultats de benchmark


Installer et configurer les éventuelles dépendances.
Dépendances principales
* PyTorch pour le deep learning
* TorchVision pour le traitement d'images
* Bibliothèques de monitoring et visualisation
* Outils de benchmark et d'analyse
Gestion des versions
* Compatibilité entre les composants
* Versions stables des frameworks
* Dépendances optimisées pour les performances


Créer les accès à l’environnement d’exécution et de configuration du service.


* Création d'environnements virtuels Python avec venv
* Gestion des dépendances via requirements.txt
* Configuration de MLflow pour le suivi des expériences
* Mise en place des variables d'environnement
* Configuration des accès GPU/CPU
* Gestion des droits d'accès aux données


Sécurisation :
* Isolation des environnements de développement et production
* Logs d'accès et monitoring
Installer et configurer les outils de monitorage disponibles avec le service intégré.


Métriques surveillées
* Performances des modèles
* Utilisation des ressources
* Temps d'exécution
* Précision des prédictions

Outils de monitoring
* Système de logs détaillés lors des différentes étapes de l'exécution du script
* Visualisation des métriques avec les différent plots
* Suivi des performances avec MLFlow


Analyse des Confusions entre Classes 
Matrices de confusion par modèle [mettre plot: confusion_matrix_{model_name}.png]


















Classes fréquemment confondues 
  

  

  











Groupes d'aliments similaires 
  

  

  



Rédiger la documentation technique.


1.  Mettre Architecture du Projet
2. Commande pour lancer le code 












________________
Conclusion


Après avoir réalisé une série de benchmarks approfondis, nous pouvons tirer plusieurs conclusions importantes :


Résultats des benchmarks :
* EfficientNet-B0 s'est révélé être le modèle le plus performant avec une précision de 71.05%


* MobileNetV3 offre le meilleur compromis vitesse/performance avec un temps d'entraînement de 1289.13s


* ResNet-50, malgré sa popularité, a montré des performances décevantes dans notre contexte


Points forts du projet :
* Système de benchmark automatisé et reproductible
* Monitoring détaillé des performances
* Documentation complète et structurée
* Flexibilité dans le choix des configurations (benchmark rapide ou complet)


Recommandations :
* Utiliser EfficientNet-B0 pour les cas nécessitant une haute précision
* Opter pour MobileNetV3 dans les environnements avec ressources limitées
* Continuer l'optimisation des hyperparamètres pour améliorer les performances


Perspectives d'évolution :
* Intégration de nouveaux modèles
* Optimisation des performances
* Amélioration du système de monitoring
* Extension à d'autres datasets alimentaires


Mon projet démontre l'importance d'une approche structurée dans l'évaluation des modèles d'IA et fournit une base solide pour de futures améliorations et comparaisons.






Annexes